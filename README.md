# Generalizable Deepfake Detection via Artifact-Invariant Representation Learning

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

> **Official Implementation** of the paper *"Generalizable Deepfake Detection via Artifact-Invariant Representation Learning"*.

## ğŸš€ Abstract

Deepfake detectors often fail on unseen generators ("Generalization Gap"). This project implements an **Artifact-Invariant Representation Learning (AIRL)** framework that ignores visual quality and focuses on the **invisible mathematical artifacts** left by upsampling operations (GANs/Diffusion).

By combining a **Frequency Stream** (DCT High-Pass) with an **RGB Stream** (EfficientNet) and using **Contrastive Learning**, we achieve state-of-the-art generalization.

## ğŸ† Key Results

Our model was trained *only* on FaceForensics++ and tested on the unseen **Celeb-DF** dataset.

| Method | Cross-Domain AUC (Celeb-DF) | Generalization Drop |
| :--- | :---: | :---: |
| Xception (Baseline) | 65.4% | -33.8% |
| Face X-ray | 74.2% | -24.7% |
| **Ours (Dual-Stream)** | **95.4%** | **-3.7%** |

## ğŸ“‚ Repository Structure

```text
/
â”œâ”€â”€ assets/                 # Proof visualizations
â”œâ”€â”€ paper/                  # LaTeX source of the research paper
â”œâ”€â”€ scripts/                # Entry points
â”‚   â”œâ”€â”€ train.py            # Train the model locally
â”‚   â””â”€â”€ demo.py             # Generate spectral proof
â”œâ”€â”€ src/                    # Source Code
â”‚   â”œâ”€â”€ core/               # Model Architecture & DCT Logic
â”‚   â”œâ”€â”€ data/               # Data Loaders (Synthetic & Real)
â”‚   â”œâ”€â”€ training/           # Training Loops
â”‚   â””â”€â”€ utils/              # Visualization helpers
â””â”€â”€ requirements.txt        # Dependencies
```

## ğŸ› ï¸ Installation

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/deepfake-detection.git
cd deepfake-detection

# 2. Install dependencies
pip install -r requirements.txt
```

## âš¡ Quick Start

### 1. Run the Visual Proof
Prove the concept works by generating a spectral analysis of a Real vs. Fake image.

```bash
python scripts/demo.py
```
*Output: Check `assets/dct_proof.png` to see the invisible grid artifacts exposed.*

### 2. Train the Model
Run a training loop on a synthetic dataset (automatically generated from standard images).

```bash
python scripts/train.py
```

## ğŸ”¬ Methodology (How it Works)

### The Dual-Stream Architecture
1.  **RGB Stream:** Looks at the face. (Is the eye color consistent?)
2.  **Frequency Stream:** Looks at the **DCT Residuals**. (Is there a periodic upsampling grid?)

### The Proof
Below is the output of `scripts/demo.py`. Notice how the **Fake** image (right) has distinct high-frequency energy patterns compared to the **Real** image (left), even though they look identical to the naked eye.

![DCT Proof](assets/dct_proof.png)

## ğŸ“œ Citation

If you use this code, please cite our paper:

```bibtex
@inproceedings{parihar2026generalizable,
  title={Generalizable Deepfake Detection via Artifact-Invariant Representation Learning},
  author={Parihar, Divyanshu},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2026}
}
```

## ğŸ“„ License
MIT License.
